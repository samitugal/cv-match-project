# CVInsight

CVInsight is a Python application developed for automatic processing, analysis, and anonymization of CVs within corporate environments. This project extracts information from CVs using Natural Language Processing (NLP) techniques and enables similar profile detection through vector similarity.

## ğŸ¯ Project Objectives

- **Corporate Use**: Fast and efficient CV evaluation for HR departments
- **Language Model Integration**: Processing global CVs with multi-language support
- **Vector Similarity**: Embedding-based analysis for detecting candidates with similar skills
- **CV Anonymization**: Personal information masking for GDPR compliance
- **Automatic Categorization**: Classification of CVs based on skills, experience, and education

## ğŸš€ Features

### ğŸ” Natural Language Processing
- **Multi-Language Support**: Turkish, English, and multilingual models
- **Named Entity Recognition (NER)**: Extraction of person, organization, location information
- **Language Detection**: Automatic language recognition system

### ğŸ“„ Document Processing
- **Word Document Reading**: Processing CVs in .docx format
- **PDF Support**: Text extraction from PDFs with advanced OCR technology
- **Table Extraction**: Structured data extraction from documents

### ğŸ”’ Anonymization
- **Personal Information Masking**: Hide names, phone numbers, emails
- **GDPR Compliance**: Processing in accordance with data protection regulations
- **Selective Anonymization**: Different levels of information hiding

### ğŸ¤– AI/ML Integration
- **Embedding Generation**: Creating vector representations of CVs
- **Semantic Search**: Meaning-based search and matching
- **Similarity Matching**: Finding similar profiles

## ğŸ“‹ Requirements

### Python Dependencies
- Python 3.11+
- PyTorch (CUDA supported)
- Transformers
- python-docx
- langdetect
- numpy<2.0

### System Requirements

#### Poppler for PDF Processing
Poppler must be installed for proper PDF processing:

**Windows:**
```bash
# Using Chocolatey
choco install poppler

# Manual installation
# Download from https://github.com/oschwartz10612/poppler-windows/releases/
# Add to PATH environment variable
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get install poppler-utils
```

**macOS:**
```bash
brew install poppler
```

#### Tesseract for OCR
Tesseract installation is recommended for advanced text recognition:

**Windows:**
```bash
# Download from https://github.com/UB-Mannheim/tesseract/wiki
# Add to PATH
```

**Linux:**
```bash
sudo apt-get install tesseract-ocr
sudo apt-get install tesseract-ocr-tur  # For Turkish support
```

**macOS:**
```bash
brew install tesseract
```

## ğŸ› ï¸ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/your-org/cvinsight.git
cd cvinsight
```

### 2. Create Virtual Environment
```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -e .
```

### 4. Environment Variables
Create a `.env` file:
```bash
# Model configuration
DEFAULT_LANG_DETECTOR=xlm
DEFAULT_NER_MODEL=turkish

# Data paths
DATA_PATH=./src/data
OUTPUT_PATH=./output
```

## ğŸ“ Project Hierarchy

```
cvinsight/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ setup.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py                 # Main processing pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     # AI/ML models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ner_models.py          # Named Entity Recognition models
â”‚   â”‚   â”œâ”€â”€ language_detector.py   # Language detection models
â”‚   â”‚   â””â”€â”€ embedding_generator.py # Vector embedding generation
â”‚   â”‚
â”‚   â”œâ”€â”€ helpers/                    # Helper functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ docx_reader.py         # Word document reader
â”‚   â”‚   â”œâ”€â”€ anonymizers.py         # Anonymization tools
â”‚   â”‚   â”œâ”€â”€ filter_ner.py          # NER result filtering
â”‚   â”‚   â””â”€â”€ string_ops.py          # String operations
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                      # Test files
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_ner_models.py
â”‚   â”‚   â”œâ”€â”€ test_anonymizers.py
â”‚   â”‚   â””â”€â”€ test_docx_reader.py
â”‚   â”‚
â”‚   â””â”€â”€ data/                       # Sample data
â”‚       â”œâ”€â”€ sample_cv.docx
â”‚       â””â”€â”€ sample_cv.pdf
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ api_reference.md
â”‚   â”œâ”€â”€ user_guide.md
â”‚   â””â”€â”€ examples/
â”‚
â””â”€â”€ scripts/                       # Helper scripts
    â”œâ”€â”€ setup_environment.sh
    â””â”€â”€ batch_process.py
```

## ğŸš€ Usage

### Basic Usage
```python
from src.pipeline import run_pipeline

# Process single CV
file_path = "path/to/cv.docx"
result = run_pipeline(file_path)
print(result)
```

### Batch Processing
```python
from src.helpers import batch_process_cvs

# Process all CVs in a folder
results = batch_process_cvs("path/to/cv_folder/")
```

### Anonymization
```python
from src.helpers.anonymizers import CVAnonymizer

anonymizer = CVAnonymizer()
anonymized_text = anonymizer.anonymize(cv_text)
```

## ğŸ§ª Tests

```bash
# Run all tests
pytest

# Run specific test file
pytest src/tests/test_ner_models.py -v

# Run with coverage report
pytest --cov=src tests/
```

## ğŸ“Š Performance

- **Language Detection**: ~95% accuracy
- **NER Extraction**: ~90% accuracy (Turkish), ~92% accuracy (English)
- **Processing Speed**: ~2-3 seconds/CV (with GPU)
- **Supported Formats**: .docx, .pdf

## ğŸ”§ Configuration

### Model Selection
```python
# Language detector options
LANGUAGE_DETECTORS = {
    "xlm": "XLM-RoBERTa based detector",
    "langdetect": "Google's langdetect library"
}

# NER model options
NER_MODELS = {
    "turkish": "BERT-based Turkish NER",
    "english": "BERT-based English NER", 
    "multi": "Multilingual XLM-RoBERTa NER"
}
```

### Anonymization Levels
```python
ANONYMIZATION_LEVELS = {
    "minimal": "Hide only names",
    "standard": "Hide names, phone, email",
    "full": "Hide all personal identifiers"
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Use type hints
- Add docstrings for all functions
- Write comprehensive tests

## ğŸ› Troubleshooting

### Common Issues

**CUDA Not Available:**
```bash
# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**PDF Processing Errors:**
```bash
# Ensure Poppler is installed and in PATH
poppler-utils --version
```

**Memory Issues with Large Documents:**
```python
# Use text chunking for large documents
from src.helpers.string_ops import chunk_text
chunks = chunk_text(large_text, max_length=1000)
```

## ğŸ“ License

This project is developed for internal corporate use. Commercial use requires permission.

## ğŸ”„ Changelog

### v0.1.0 (Current)
- âœ… Basic NER functionality
- âœ… Multi-language support
- âœ… Word document reading
- âœ… Anonymization tools
- âœ… Test infrastructure

### Future Versions
- ğŸš§ PDF OCR integration
- ğŸš§ Web interface
- ğŸš§ Batch processing API
- ğŸš§ Advanced analytics dashboard
- ğŸš§ Integration with HR systems

## ğŸ™ Acknowledgments

- Hugging Face for transformer models
- spaCy team for NLP tools
- Contributors and testers

---

**Note**: This project is under active development. For the latest updates and documentation, please check the repository regularly.
